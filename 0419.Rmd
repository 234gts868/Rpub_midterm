---
title: "group 14_midterm"
output: html_document
---

```{r setup, include=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(d3heatmap)
library(googleVis)

customer <- read_csv("data/olist_customers_dataset.csv")
item <- read_csv("data/olist_order_items_dataset.csv")
review <- read_csv("data/olist_order_reviews_dataset.csv")         
order <- read_csv("data/olist_orders_dataset.csv")
product <-read_csv("data/olist_products_dataset.csv")
seller <-read_csv("data/olist_sellers_dataset.csv")
translation <-read_csv("data/product_category_name_translation.csv")
lead <-read_csv("data/olist_closed_deals_dataset.csv")
review$review_score = as.factor(review$review_score)
review_tran <- read_csv("data/olist_order_reviews_dataset_translated.csv")
# ORIS<- merge(products,order_items,by= "product_id")
# ORIS <- merge(ORIS ,order_reviews,by= "order_id")
# ORIS <- merge(ORIS,translation,by= "product_category_name")
# ORIS <-merge(ORIS,sellers,by= "seller_id")
# ORIS <-merge(ORIS,orders,by= "order_id")
# ORIS <-merge(ORIS,customer,by= "customer_id")


#ORIS$review_score=as.factor(ORIS$review_score)


```


```{r,include=FALSE}
ORIS = order %>%
  inner_join(review) %>%
  inner_join(item) %>%
  inner_join(seller)
```


>對延遲訂單的簡單分析

- 比較估計的交付天數和交付的實際天數
```{r}
ORIS$delaydays=
  difftime(as.Date(ORIS$order_delivered_customer_date,na.rm=TRUE),
           as.Date(ORIS$order_estimated_delivery_date,na.rm=TRUE),units = "days")

ORIS = ORIS %>%
  filter(!is.na(delaydays))

```

- 估計均值，標準差和方差
```{r,warning=FALSE}
mean(ORIS$delaydays)
sd(ORIS$delaydays)
ggplot(ORIS ,aes(delaydays)) +
  geom_histogram(bins = 30) + xlim(-100,100)

# 7294 delay
table(ORIS$delaydays>0)
```
- 以月為單位檢查行為

```{r,message=FALSE}
library(lubridate)
ORIS$delay=ORIS$delaydays>0   #delay or not   
ORIS$order_purchase_timestamp=as.Date(ORIS$order_purchase_timestamp,na.rm=TRUE)

ggplot(ORIS, aes(month(ORIS$order_purchase_timestamp), fill =delay )) + geom_bar()
```
**3和11月延遲訂單數最多**

```{r}

delay_data  = ORIS %>%
  select(order_purchase_timestamp) 
delay_data$month=format(delay_data$order_purchase_timestamp,'%Y%m') 
delay_data$day=format(delay_data$order_purchase_timestamp,'%d') 

table(as.numeric(delay_data$month),as.numeric(delay_data$day)) %>%as.data.frame.matrix %>% 
  {log(.+1)} %>%  
  d3heatmap(F,F,color=cm.colors(17))

```


- 3 ,11 month delay analysis
```{r,include=FALSE}

ORIS%>%
  filter(month(ORIS$order_purchase_timestamp)==c(3,11))






```

```{r,message=FALSE}
ORIP = order %>%
  inner_join(review) %>%
  inner_join(item) %>%
  inner_join(product) %>%
  inner_join(translation) %>%
  left_join(ORIS,by ="order_id")
```
##畫 類別 然後 有星星的 X 軸是年月日  延遲訂單的天數 預計到達的天數

```{r}
count(ORIP,product_category_name_english,delay) %>%  
  filter(product_category_name_english=='baby')
```


```{r}
sort(table(ORIP$product_category_name_english),decreasing = T)
ORIP%>%
  filter(!is.na(delay)) %>%
  group_by(product_category_name_english)%>% 
  summarise(
    ratio=sum(delay)/n()
  ) %>%  
  top_n(10) %>%
  mutate(new_x=reorder(product_category_name_english,ratio)) %>% 
ggplot(aes(new_x,ratio)) +
  geom_bar(stat='identity',fill = "steelblue")+ 
  coord_flip()


# draw a order plot by category
# topn =10
# by money ?

```


- delay天數跟review_score之間的關係
```{r}
ORIS$delaydays = as.numeric(ORIS$delaydays)

ORIS_delay=ORIS %>%
  filter(delaydays<50) %>%
  filter(delaydays>0)%>%
   mutate( binwidth = delaydays %/% 5 )
# mutate( binwidth = paste(as.character((ORIS$A %/% 5)*5-4) ,"-", as.character((ORIS$A %/% 5)*5)))
#w = paste(as.character((ORIS$B %/% 5)*5-4) ,zzz, as.character((ORIS$B %/% 5)*5))
#w

#  percentage of score ~ day
ORIS_delay%>%
ggplot(aes(binwidth, fill=review_score)) +
  geom_bar(position = 'fill') +
  geom_text(data = . %>% 
              group_by(binwidth, review_score) %>%
              tally() %>%
              mutate(p = n / sum(n)) %>%
              ungroup(),
            aes(y = p, label = scales::percent(p)),
            position = position_stack(vjust = 0.5),
            show.legend = FALSE)
## 
ORIS_nodelay=ORIS %>%
  filter(delaydays <0)%>%
  mutate( binwidth = delaydays %/% 10 )


ORIS_nodelay%>%
  ggplot(aes(binwidth, fill=review_score)) +
  geom_bar(position = 'fill') +
  geom_text(size = 3,data = . %>% 
              group_by(binwidth, review_score) %>%
              tally() %>%
              mutate(p = n / sum(n)) %>%
              ungroup(),
            aes(y = p, label = scales::percent(p)),
            position = position_stack(vjust = 0.5),
            show.legend = FALSE)

```

### 使用翻譯完的留言資料做分析
```{r message=FALSE, warning=FALSE}
library(tidytext)
library(data.table)
library(tidyr)
library(ggplot2)
library(tm)
library(wordcloud2)
```

```{r}
review_tran_m = review_tran %>%
  select(translate_message)

colnames(review_tran_m) = "text"

data(stop_words) #add stop word

review_tran_conut =review_tran_m%>%
  filter(!is.na(text))%>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(word,sort=T)
  
review_tran_conut$word = removeNumbers(review_tran_conut$word)
review_tran_conut = review_tran_conut %>% 
  filter(!word =="")


review_tran_conut %>%
  top_n(10) %>%  # find top 10
  mutate(word = reorder(word, n)) %>%  
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

review_tran_conut %>%
  filter(n >200) %>%
  wordcloud2()
```
#draw a texplot wordcloud
```{r}
library(tm)
library(stringr)
dtm =review_tran$translate_message %>% 
  iconv(to = "utf-8", sub="") %>% 
  str_trim(.) %>%
  toupper() %>%
  VectorSource %>% Corpus %>% 
  tm_map(content_transformer(tolower)) %>% 
  tm_map(removePunctuation) %>% 
  tm_map(stemDocument) %>% 
  DocumentTermMatrix %>% 
  removeSparseTerms(0.998)
dtm  # (documents: 14156, terms: 1030)
dtm_tmp=dtm
```
```{r}
library(slam)
tfidf = tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) *
  log2(nrow(dtm)/col_sums(dtm > 0))
summary(tfidf)

dtm=dtm_tmp
dtm = dtm[, tfidf > 0.24 ]
dtm = dtm[,order(-col_sums(dtm))]
dim(dtm)
```



```{r}
library(Rtsne)
n = 200
tsne = dtm[, 1:n] %>% as.data.frame.matrix %>% 
  scale %>% t %>% Rtsne(
    check_duplicates = FALSE, theta=0.0, max_iter=3200)
```

```{r}
Y = tsne$Y              # tSNE coordinates
d = dist(Y)             # distance matrix
hc = hclust(d)          # hi-clustering
K = 20              # number of clusters 
g = cutree(hc,K)        # cut into K clusters
table(g) %>% as.vector %>% sort         # sizes of clusters
```

```{r}
# install.packages('randomcoloR')
library(randomcoloR)
library(wordcloud)
library(slam)
wc = col_sums(dtm[,1:n])
colors = distinctColorPalette(K)
png("./olist.png", width=3200, height=1800)
textplot(
  Y[,1], Y[,2], colnames(dtm)[1:n], show=F, 
  col=colors[g],
  cex= 3 + 1.25 * sqrt(wc/mean(wc)),
  font=2)
dev.off()
```

